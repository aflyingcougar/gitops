---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: ark
spec:
  interval: 5m
  chart:
    spec:
      chart: ark-cluster
      version: 0.2.1
      sourceRef:
        kind: HelmRepository
        name: ark-server-charts
        namespace: flux-system
  values:
    nameOverride: ""
    fullnameOverride: ""
    commonLabels: {}
    commonAnnotations:
      io.cilium/lb-ipam-ips: "${ARK_CLUSTER_SERVICE_LB}"
      io.cilium/lb-ipam-sharing-key: ark-cluster
    nodeSelector:
      ${FAMILY_DOMAIN}/role: gameserver
    affinity: {}
    tolerations: []
    securityContext:
      runAsUser: 2565
      fsGroup: 2565
    podLabels: {}
    podAnnotations:
      reloader.stakater.com/auto: "true"
    podSecurityContext:
      capabilities:
        drop:
          - ALL
        add:
          - CHOWN
          - NET_BIND_SERVICE
      readOnlyRootFilesystem: true
      runAsNonRoot: false
    topologySpreadConstraints: {}

    image:
      registry: docker.io
      repository: drpsychick/arkserver
      tag: lunar
      pullSecrets: []
      pullPolicy: Always

    updateStrategy:
      type: Recreate

    restartPolicy: Always

    # Time for the server to shutdown gracefully
    terminationGracePeriodSeconds: 60

    # Defaults to 1, we set this to 0 so servers don't start automatically after deploy
    #
    replicaCount: 0

    # Attach pod directly to host network
    # Implies: `service.enabled: false`
    # Mutually exclusive: `hostPort`
    hostNetwork: false

    # Attach specific ports to host node.
    # Implies: `service.enabled: false`
    # Mutually exclusive: `hostNetwork`
    hostPort: false

    # set to "ClusterFirstWithHostNet" when hostNetwork=true
    #
    # dnsPolicy: ClusterFirst

    # Cluster name
    clusterName: arkcluster

    # Mods available in the cluster and enabled by default on all servers.
    # Mods are updated with the game and can be overwritten per server.
    mods: []
    #  - "731604991"
    #  - "889745138"
    #  - "893904615"
    #  - "1404697612"
    #  - "621154190"
    #  - "564895376"
    #  - "931434275"

    # Set RCON password for the whole cluster
    rcon:
      password: ${ARK_SERVER_RCON_PASSWORD}

    # Global extraEnvVars for all servers
    extraEnvVars:
      - name: am_arkwarnminutes
        value: "15"

    # Global custom game settings can be overwritten per server
    #customConfigMap:
    # GameIni: ark-server-global-gameini
    # GameUserSettingsIni: ark-server-global-user-settings-ini
    # EngineIni: ark-server-global-engine-ini
    # crontab: ""

    # Servers in the ARK cluster
    servers:
      # one entry for each server in the cluster
      theisland:
        # updateOnStart should be enabled only on the first server
        updateOnStart: true
        sessionName: "The Island"
        message: "Welcome to The Island"
        # map: TheIsland, Ragnarok, CrystalIsles, Aberration_P, ScorchedEarth_P, Extinction, ...
        map: TheIsland
        password: "${ARK_SERVER_PASSWORD}"
        maxPlayers: 10
        # xpMultiplier is added to default GameUserSettings.ini
        # if you use `customConfigMap.GameUserSettingsIni` make sure to include it there
      #  xpMultiplier: 6
        extraEnvVars:
          - name: am_arkwarnminutes
            value: "15"
        # ports must be the same on external and internal
        ## we don't need a service abtraction as every pod is a single server with dedicated ports
        # a service with nodePort would be "right" configuration, but for latency reasons I'd skip it.
        # with service: public:30200 -> [nodeport:30200] -> service:$gameudp -> pod:30200
        # hostnetwork (no service!): public:30200 -> node=pod:30200
        # pod hostPort (through service): public:30200 -> node=pod:30200
        # difference hostPort hostNetwork : Port only exposes a single port
        ports:
          queryudp: 27010
          gameudp: 7770
          rcon: 32330
        # override mods for a single server
        # mods: []
        rcon:
          password: "${ARK_SERVER_RCON_PASSWORD}"
        resources:
          requests:
            cpu: 2
            memory: 8Gi
          limits:
            memory: 16Gi
        # customConfigMap:
        #   GameIni: |
        #     # Extinction Game.ini
        #   GameUserSettingsIni: |
        #     # Extinction GameUserSettings.ini
        #     [ServerSettings]
        #     XPMultiplier=6
        #   EngineIni: |
        #     # Extinction Engine.ini

    # Containers' resource requests and limits
    # ref: http://kubernetes.io/docs/user-guide/compute-resources/
    #
    resources:
      requests:
        cpu: 2
        memory: 8Gi
      limits:
        memory: 16Gi

    # Default ports used by the container. Can be set per server.
    # ARK communicates ports to the client, so make sure the container port matches the external port!
    # Using these default settings for a cluster only makes sense if you have an IP for each server.
    containerPorts:
      gameudp: 7777
      queryudp: 27015
      rcon: 27020

    service:
      # enable a service per server
      enabled: true
      # externalTrafficPolicy: Local
      type: LoadBalancer
      # Enable metallb shared ip
      metallb_shared_ip: false

    # Enable persistence using Persistent Volume Claims
    # ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
    #
    persistence:
      enabled: false

      # use generic existing volume names prefixed with <cluster-name>: -game, -cluster, -<server-name>
      #
      existingVolumes: false

      # game files from steam, the largest volume, includes installed mods
      game:
        accessModes:
          - ReadOnlyMany
          - ReadWriteMany
          - ReadWriteOnce
        size: 30Gi
        annotations: {}

        # mountPath is used regardless if `persistence` is enabled
        # this is the mount point in the pod image
        mountPath: /arkserver

      # shared cluster files
      cluster:
        accessModes:
          - ReadWriteMany
        size: 200Mi
        annotations: {}
        mountPath: /arkserver/ShooterGame/Saved/clusters

      # contains the world save game and configuration files
      # keeping a backup of this is enough to get your server back up
      save:
        # A named, existing Persistent Volume
        #
        # existingVolume:

        # A manually managed Persistent Volume Claim, if none given, the PVC
        # will be created with the name: <cluster-name>-<server-name>
        #
        # existingClaim:

        # volumeMode defines what type of volume is required by the claim.
        # Value of Filesystem is implied when not included in claim spec.
        #
        # volumeMode: Filesystem

        # PV Storage Class
        # If defined, storageClassName: <storageClass>
        # If set to "-", storageClassName: "", which disables dynamic provisioning
        # If undefined (the default) or set to null, no storageClassName spec is
        # set, choosing the default provisioner.
        #
        # storageClass: "local-storage"

        # PVC Access Modes
        accessModes:
          - ReadWriteOnce

        # PVC size
        size: 2Gi

        annotations: {}

        # The path the volume will be mounted at
        mountPath: /arkserver/ShooterGame/Saved


    # Startup and Liveness probe values
    # Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
    startupProbe:
      # 120s + 60*10s = 720s max
      initialDelaySeconds: 120
      failureThreshold: 60
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1
    livenessProbe:
      # unhealthy after max 3*10s = 30s
      initialDelaySeconds: 10
      failureThreshold: 3
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1

    serviceAccount:
      # Specifies whether a service account should be created
      create: true
      # Annotations to add to the service account
      annotations: {}
      # The name of the service account to use.
      # If not set and create is true, a name is generated using the fullname template
      name: ""

    extraInitContainers: []
    extraVolumeMounts: []
    extraVolumes: []
